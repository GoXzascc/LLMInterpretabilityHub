auxk_alpha: 0.03125
batch_size: 128
config_save_path: ./scripts/trainer_{model_name}_Layer{model_layer}_{sae_name}SAE_{dataset}.yaml
ctx_len: 1024
dataset: monology/pile-uncopyrighted
decay_start: null
device: cuda
dictionary_factor: 8
k: 50
log_path: ./logs
lr: 0.001
model_layer: 3
model_name: EleutherAI/pythia-70m
n_ctxs: 1000
sae_name: topk
save_steps: 1000
seed: 42
steps: 2000
threshold_beta: 0.999
threshold_start_step: 1000
verbose: true
